{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8b7bb5",
   "metadata": {},
   "source": [
    "# Agents in Team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d02972",
   "metadata": {},
   "source": [
    "### A single Agent can only say create a short story for us.\n",
    "### but with a team whre many agents work together towards a common goal they can help us in writing or even helping to review, edit etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ecc8f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4o', api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6361f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client_2 = OpenAIChatCompletionClient(model='gpt-4',api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4752e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "dsa_solver = AssistantAgent(\n",
    "    name = 'Complex_DSA_Solver',\n",
    "    model_client=model_client,\n",
    "    description='A DSA solver',\n",
    "    system_message=\"You give code in python to solve complex DSA problems. Give under 100 words\"\n",
    ")\n",
    "\n",
    "code_reviewer = AssistantAgent(\n",
    "    name = 'CODE_REVEIWER',\n",
    "    model_client=model_client_2,\n",
    "    description='A Code Reviewer',\n",
    "    system_message=\"You review the code given by the complex_dsa_solver and make sure it is optimized.Give under 10 words\"\n",
    ")\n",
    "\n",
    "code_editor = AssistantAgent(\n",
    "    name = 'CODE_EDITOR',\n",
    "    model_client=model_client,\n",
    "    description='A Code editor',\n",
    "    system_message=\"You make the code easy to understand and add comments wherever required.Give under 10 words\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d2b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source='User' models_usage=None metadata={} content='Write a simple Hello world code ?' type='TextMessage' \n",
      "\n",
      " \n",
      "\n",
      "source='Complex_DSA_Solver' models_usage=RequestUsage(prompt_tokens=63, completion_tokens=10) metadata={} content='```python\\nprint(\"Hello, world!\")\\n```' type='TextMessage' \n",
      "\n",
      " \n",
      "\n",
      "source='CODE_REVEIWER' models_usage=RequestUsage(prompt_tokens=105, completion_tokens=6) metadata={} content='Code is efficient and optimal.' type='TextMessage' \n",
      "\n",
      " \n",
      "\n",
      "source='CODE_EDITOR' models_usage=RequestUsage(prompt_tokens=133, completion_tokens=9) metadata={} content='Agreed, itâ€™s straightforward and effective.' type='TextMessage' \n",
      "\n",
      " \n",
      "\n",
      "source='Complex_DSA_Solver' models_usage=RequestUsage(prompt_tokens=109, completion_tokens=20) metadata={} content='Thank you for the feedback! If you need any modifications or further assistance, feel free to ask.' type='TextMessage' \n",
      "\n",
      " \n",
      "\n",
      "source='CODE_REVEIWER' models_usage=RequestUsage(prompt_tokens=161, completion_tokens=6) metadata={} content='Code is optimized and efficient.' type='TextMessage' \n",
      "\n",
      " \n",
      "\n",
      "source='CODE_EDITOR' models_usage=RequestUsage(prompt_tokens=192, completion_tokens=6) metadata={} content=\"Yes, it's perfectly concise.\" type='TextMessage' \n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[dsa_solver,code_reviewer,code_editor],\n",
    "    max_turns=15 # -----># maximum number of Message before it stops between the agents.\n",
    ")\n",
    "\n",
    "async def test_team():\n",
    "    task = TextMessage(content='Write a simple Hello world code ?',source='User')\n",
    "    \n",
    "    result = await team.run(task=task)\n",
    "\n",
    "    for each_agent_message in result.messages:\n",
    "        print(f'{((each_agent_message))} ' )\n",
    "        print('\\n \\n')\n",
    "\n",
    "\n",
    "await test_team()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d89f6b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user source='user' models_usage=None metadata={} content='Write a simple Hello world code ?' type='TextMessage'\n",
      "Complex_DSA_Solver source='Complex_DSA_Solver' models_usage=RequestUsage(prompt_tokens=36, completion_tokens=24) metadata={} content='Certainly! Here\\'s a simple \"Hello, World!\" program in Python:\\n\\n```python\\nprint(\"Hello, World!\")\\n```' type='TextMessage'\n",
      "CODE_REVEIWER source='CODE_REVEIWER' models_usage=RequestUsage(prompt_tokens=77, completion_tokens=11) metadata={} content='Optimized, adheres to best practices and efficient.' type='TextMessage'\n",
      "CODE_EDITOR source='CODE_EDITOR' models_usage=RequestUsage(prompt_tokens=92, completion_tokens=9) metadata={} content=\"Thank you! It's straightforward and beginner-friendly.\" type='TextMessage'\n",
      "Complex_DSA_Solver source='Complex_DSA_Solver' models_usage=RequestUsage(prompt_tokens=101, completion_tokens=17) metadata={} content=\"Glad you find it optimal! It's efficient and follows Python's simplicity and readability principles.\" type='TextMessage'\n",
      "CODE_REVEIWER source='CODE_REVEIWER' models_usage=RequestUsage(prompt_tokens=138, completion_tokens=7) metadata={} content='Code is already simplified and efficient.' type='TextMessage'\n",
      "CODE_EDITOR source='CODE_EDITOR' models_usage=RequestUsage(prompt_tokens=149, completion_tokens=9) metadata={} content=\"Great! It's concise and easy to understand.\" type='TextMessage'\n",
      "Stop Reason: Maximum number of turns 6 reached.\n"
     ]
    }
   ],
   "source": [
    "await team.reset()  # Reset the team for a new task.\n",
    "from autogen_agentchat.base import TaskResult\n",
    "\n",
    "async for message in team.run_stream(task=\"Write a simple Hello world code ?\"):  # type: ignore\n",
    "    if isinstance(message, TaskResult):\n",
    "        print(\"Stop Reason:\", message.stop_reason)\n",
    "    else:\n",
    "        print(message.source,message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c07d1c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a simple Hello world code.\n",
      "---------- TextMessage (Complex_DSA_Solver) ----------\n",
      "```python\n",
      "def hello_world():\n",
      "    print(\"Hello, World!\")\n",
      "\n",
      "hello_world()\n",
      "```\n",
      "---------- TextMessage (CODE_REVEIWER) ----------\n",
      "Code is simple and optimized.\n",
      "---------- TextMessage (CODE_EDITOR) ----------\n",
      "Thank you! Glad you found it clear.\n",
      "---------- TextMessage (Complex_DSA_Solver) ----------\n",
      "You're welcome! If you need further assistance or modifications, feel free to ask.\n",
      "---------- TextMessage (CODE_REVEIWER) ----------\n",
      "No changes needed, code is optimized.\n",
      "---------- TextMessage (CODE_EDITOR) ----------\n",
      "Great! Thanks for the feedback.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Write a simple Hello world code.', type='TextMessage'), TextMessage(source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=36, completion_tokens=18), metadata={}, content='```python\\ndef hello_world():\\n    print(\"Hello, World!\")\\n\\nhello_world()\\n```', type='TextMessage'), TextMessage(source='CODE_REVEIWER', models_usage=RequestUsage(prompt_tokens=70, completion_tokens=6), metadata={}, content='Code is simple and optimized.', type='TextMessage'), TextMessage(source='CODE_EDITOR', models_usage=RequestUsage(prompt_tokens=81, completion_tokens=9), metadata={}, content='Thank you! Glad you found it clear.', type='TextMessage'), TextMessage(source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=90, completion_tokens=16), metadata={}, content=\"You're welcome! If you need further assistance or modifications, feel free to ask.\", type='TextMessage'), TextMessage(source='CODE_REVEIWER', models_usage=RequestUsage(prompt_tokens=123, completion_tokens=8), metadata={}, content='No changes needed, code is optimized.', type='TextMessage'), TextMessage(source='CODE_EDITOR', models_usage=RequestUsage(prompt_tokens=138, completion_tokens=7), metadata={}, content='Great! Thanks for the feedback.', type='TextMessage')], stop_reason='Maximum number of turns 6 reached.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "await team.reset()  # Reset the team for a new task.\n",
    "await Console(team.run_stream(task=\"Write a simple Hello world code.\"))  # Stream the messages to the console.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bc0ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "conitnue.\n",
      "---------- TextMessage (Complex_DSA_Solver) ----------\n",
      "It seems you might want additional information or another task. Could you please clarify?\n",
      "---------- TextMessage (CODE_REVEIWER) ----------\n",
      "Proceeding with the next task.\n",
      "---------- TextMessage (CODE_EDITOR) ----------\n",
      "Let's continue! Any specific task in mind?\n",
      "---------- TextMessage (Complex_DSA_Solver) ----------\n",
      "Please provide the next task or question you'd like help with.\n",
      "---------- TextMessage (CODE_REVEIWER) ----------\n",
      "Continuing with optimization.\n",
      "---------- TextMessage (CODE_EDITOR) ----------\n",
      "Great! Share the code for further optimization.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='conitnue.', type='TextMessage'), TextMessage(source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=165, completion_tokens=16), metadata={}, content='It seems you might want additional information or another task. Could you please clarify?', type='TextMessage'), TextMessage(source='CODE_REVEIWER', models_usage=RequestUsage(prompt_tokens=202, completion_tokens=7), metadata={}, content='Proceeding with the next task.', type='TextMessage'), TextMessage(source='CODE_EDITOR', models_usage=RequestUsage(prompt_tokens=215, completion_tokens=9), metadata={}, content=\"Let's continue! Any specific task in mind?\", type='TextMessage'), TextMessage(source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=218, completion_tokens=12), metadata={}, content=\"Please provide the next task or question you'd like help with.\", type='TextMessage'), TextMessage(source='CODE_REVEIWER', models_usage=RequestUsage(prompt_tokens=253, completion_tokens=5), metadata={}, content='Continuing with optimization.', type='TextMessage'), TextMessage(source='CODE_EDITOR', models_usage=RequestUsage(prompt_tokens=265, completion_tokens=9), metadata={}, content='Great! Share the code for further optimization.', type='TextMessage')], stop_reason='Maximum number of turns 6 reached.')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream(task=\"conitnue.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc374eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. User Proxy \n",
    "\n",
    "2. Termination Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337339d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5d12b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "add_1_agent_first = AssistantAgent(\n",
    "    name = 'add_1_agent_first',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Add 1 to the number, first number is 0. Give result as output\"\n",
    ")\n",
    "\n",
    "add_1_agent_second = AssistantAgent(\n",
    "    name = 'add_1_agent_second',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Add 1 to the number you got from previous run. Give result as output.\"\n",
    ")\n",
    " \n",
    "add_1_agent_third = AssistantAgent(\n",
    "    name = 'add_1_agent_third',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Add 1 to the number from previous run. Give result as output.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5720ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_increment_team = RoundRobinGroupChat(participants=[add_1_agent_first,add_1_agent_second,add_1_agent_third],max_turns=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0355de1d",
   "metadata": {},
   "source": [
    "# Resume a Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80bf69e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "The result of adding 1 to 0 is 1.\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "The result of adding 1 to 1 is 2.\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "The result of adding 1 to 2 is 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=24, completion_tokens=13), metadata={}, content='The result of adding 1 to 0 is 1.', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=46, completion_tokens=13), metadata={}, content='The result of adding 1 to 1 is 2.', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=66, completion_tokens=13), metadata={}, content='The result of adding 1 to 2 is 3.', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(my_increment_team.run_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "699010d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "The result of adding 1 to 3 is 4.\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "The result of adding 1 to 4 is 5.\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "The result of adding 1 to 5 is 6.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=86, completion_tokens=13), metadata={}, content='The result of adding 1 to 3 is 4.', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=108, completion_tokens=13), metadata={}, content='The result of adding 1 to 4 is 5.', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=127, completion_tokens=13), metadata={}, content='The result of adding 1 to 5 is 6.', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(my_increment_team.run_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "The result of adding 1 to 6 is 7.\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "The result of adding 1 to 7 is 8.\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "The result of adding 1 to 8 is 9.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=148, completion_tokens=13), metadata={}, content='The result of adding 1 to 6 is 7.', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=170, completion_tokens=13), metadata={}, content='The result of adding 1 to 7 is 8.', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=188, completion_tokens=13), metadata={}, content='The result of adding 1 to 8 is 9.', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await team.reset()\n",
    "await Console(my_increment_team.run_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4361f3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "The number is 0. If you add 1 to it, the result is 1.\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "The result is 2.\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "The result is 3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=24, completion_tokens=20), metadata={}, content='The number is 0. If you add 1 to it, the result is 1.', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=53, completion_tokens=6), metadata={}, content='The result is 2.', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=66, completion_tokens=6), metadata={}, content='The result is 3.', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await my_increment_team.reset()\n",
    "await Console(my_increment_team.run_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f13f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseGroupChat.save_state of <autogen_agentchat.teams._group_chat._round_robin_group_chat.RoundRobinGroupChat object at 0x108b6b1a0>>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f10394c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogen-lc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
